{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce GTX 1650 with Max-Q Design'"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import T_co\n",
    "\n",
    "gpu = torch.cuda.current_device()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "epoch -> 1 forward and backward pass of all training samples\n",
    "\n",
    "batch size -> num. of training samples in one forward and backward pass\n",
    "\n",
    "num. of iterations -> num. of passes, each pass using [batch_size] number of samples\n",
    "\n",
    "e.g.:\n",
    "\n",
    "100 samples, batch size=20 -> 100/20 = 5 iterations for each epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # data loading\n",
    "        wine = np.loadtxt(\"./data/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "\n",
    "        self.X = torch.from_numpy(wine[:, 1:])\n",
    "        self.y = torch.from_numpy(wine[:, [0]])\n",
    "        self.n_samples = wine.shape[0]\n",
    "\n",
    "    def __getitem__(self, index)-> T_co:\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = WineDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n         1.0650e+03]),\n tensor([1.]))"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "\n",
    "features, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.3270e+01, 4.2800e+00, 2.2600e+00, 2.0000e+01, 1.2000e+02, 1.5900e+00,\n          6.9000e-01, 4.3000e-01, 1.3500e+00, 1.0200e+01, 5.9000e-01, 1.5600e+00,\n          8.3500e+02],\n         [1.2000e+01, 9.2000e-01, 2.0000e+00, 1.9000e+01, 8.6000e+01, 2.4200e+00,\n          2.2600e+00, 3.0000e-01, 1.4300e+00, 2.5000e+00, 1.3800e+00, 3.1200e+00,\n          2.7800e+02],\n         [1.3770e+01, 1.9000e+00, 2.6800e+00, 1.7100e+01, 1.1500e+02, 3.0000e+00,\n          2.7900e+00, 3.9000e-01, 1.6800e+00, 6.3000e+00, 1.1300e+00, 2.9300e+00,\n          1.3750e+03],\n         [1.4020e+01, 1.6800e+00, 2.2100e+00, 1.6000e+01, 9.6000e+01, 2.6500e+00,\n          2.3300e+00, 2.6000e-01, 1.9800e+00, 4.7000e+00, 1.0400e+00, 3.5900e+00,\n          1.0350e+03]]),\n tensor([[3.],\n         [2.],\n         [1.],\n         [1.]]))"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data iterator from data loader\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "# each iteration will return a single batch\n",
    "features, labels = data_iter.next()\n",
    "\n",
    "features, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch: 1/2, step 1/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 2/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 3/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 4/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 5/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 6/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 7/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 8/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 9/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 10/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 11/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 12/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 13/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 14/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 15/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 16/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 17/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 18/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 19/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 20/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 21/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 22/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 23/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 24/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 25/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 26/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 27/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 28/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 29/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 30/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 31/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 32/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 33/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 34/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 35/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 36/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 37/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 38/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 39/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 40/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 41/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 42/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 43/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 44/45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/2, step 45/45, inputs: torch.Size([2, 13])\n",
      "epoch: 2/2, step 1/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 2/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 3/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 4/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 5/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 6/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 7/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 8/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 9/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 10/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 11/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 12/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 13/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 14/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 15/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 16/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 17/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 18/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 19/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 20/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 21/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 22/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 23/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 24/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 25/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 26/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 27/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 28/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 29/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 30/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 31/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 32/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 33/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 34/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 35/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 36/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 37/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 38/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 39/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 40/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 41/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 42/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 43/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 44/45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/2, step 45/45, inputs: torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# a sample training loop\n",
    "\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / 4)\n",
    "\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "\n",
    "        # do forward, backward, update\n",
    "        print(f\"epoch: {epoch}/{num_epochs}, step {i+1}/{n_iterations}, inputs: {inputs.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}